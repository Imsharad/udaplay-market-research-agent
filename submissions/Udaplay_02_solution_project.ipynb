{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# UdaPlay Part 2: AI Agent Development\n",
    "\n",
    "In this notebook, we'll build an intelligent agent that combines local knowledge with web search capabilities.\n",
    "\n",
    "## Objectives:\n",
    "1. Implement three tools: `retrieve_game`, `evaluate_retrieval`, and `game_web_search`\n",
    "2. Build a stateful agent that manages conversation and tool usage\n",
    "3. Implement the workflow: RAG â†’ Evaluate â†’ Web Search (if needed)\n",
    "4. Demonstrate the agent with example queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Detected Vocareum OpenAI API key - configuring for Vocareum endpoint\n",
      "âœ… Environment variables loaded.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install -q chromadb openai python-dotenv requests pydantic pdfplumber\n",
    "\n",
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# Add the project's lib directory to the Python path\n",
    "sys.path.append('../projects/building-agents/src/project/starter')\n",
    "\n",
    "# Import our custom modules\n",
    "from lib.llm import LLM\n",
    "from lib.agents import Agent, AgentState\n",
    "from lib.tooling import tool, Tool\n",
    "from lib.vector_db import VectorStore\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination\n",
    "from lib.messages import AIMessage, UserMessage, SystemMessage, ToolMessage\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure for Vocareum if using voc- keys\n",
    "if os.environ.get(\"OPENAI_API_KEY\", \"\").startswith(\"voc-\"):\n",
    "    print(\"Detected Vocareum OpenAI API key - configuring for Vocareum endpoint\")\n",
    "    os.environ['OPENAI_API_BASE'] = 'https://openai.vocareum.com/v1'\n",
    "\n",
    "# Verify essential API keys\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in environment\"\n",
    "assert os.getenv(\"CHROMA_OPENAI_API_KEY\"), \"CHROMA_OPENAI_API_KEY not found in environment\"\n",
    "assert os.getenv(\"TAVILY_API_KEY\"), \"TAVILY_API_KEY not found in environment\"\n",
    "\n",
    "print(\"âœ… Environment variables loaded.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Initialize Vector Store Connection\n",
    "\n",
    "First, we'll connect to the vector store we created in Part 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to vector store. Sample docs: 1\n"
     ]
    }
   ],
   "source": [
    "# Vector Store Connection (using same VocareumVectorStoreManager as Part 1)\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "class VocareumVectorStoreManager:\n",
    "    \"\"\"Same vector store manager as Part 1 to ensure compatibility.\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str):\n",
    "        # Use persistent client so data survives between script runs\n",
    "        self.client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        self.embedding_function = self._create_embedding_function(openai_api_key)\n",
    "\n",
    "    def _create_embedding_function(self, api_key: str):\n",
    "        if api_key.startswith(\"voc-\"):\n",
    "            return embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=api_key, api_base=\"https://openai.vocareum.com/v1\"\n",
    "            )\n",
    "        return embedding_functions.OpenAIEmbeddingFunction(api_key=api_key)\n",
    "\n",
    "    def get_store(self, name: str):\n",
    "        try:\n",
    "            return VectorStore(self.client.get_collection(name=name))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "vector_manager = VocareumVectorStoreManager(openai_api_key=os.getenv(\"CHROMA_OPENAI_API_KEY\"))\n",
    "\n",
    "vector_store = vector_manager.get_store(\"udaplay_games\")\n",
    "\n",
    "if vector_store:\n",
    "    test_results = vector_store.get(limit=1)\n",
    "    print(f\"âœ… Connected to vector store. Sample docs: {len(test_results['ids'])}\")\n",
    "else:\n",
    "    print(\"âŒ Could not locate 'udaplay_games' vector store.\")\n",
    "    print(\"Please run Part 1 first!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Implement Agent Tools\n",
    "\n",
    "Now we'll implement the three required tools for our agent.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 games\n",
      "First result: PokÃ©mon Ruby and Sapphire (2002)\n"
     ]
    }
   ],
   "source": [
    "# Tool 1: retrieve_game - Search the vector database\n",
    "@tool\n",
    "def retrieve_game(query: str, n_results: int = 3) -> Dict:\n",
    "    \"\"\"Search the vector database for game information.\"\"\"\n",
    "    try:\n",
    "        results = vector_store.query(query_texts=[query], n_results=n_results)\n",
    "        formatted_results = []\n",
    "        if results[\"documents\"] and results[\"documents\"][0]:\n",
    "            for doc, distance, metadata in zip(\n",
    "                results[\"documents\"][0],\n",
    "                results[\"distances\"][0],\n",
    "                results[\"metadatas\"][0],\n",
    "            ):\n",
    "                similarity = 1 - distance\n",
    "                formatted_results.append(\n",
    "                    {\n",
    "                        \"name\": metadata[\"name\"],\n",
    "                        \"platform\": metadata[\"platform\"],\n",
    "                        \"genre\": metadata[\"genre\"],\n",
    "                        \"publisher\": metadata[\"publisher\"],\n",
    "                        \"release_year\": metadata[\"release_year\"],\n",
    "                        \"description\": metadata[\"description\"],\n",
    "                        \"similarity_score\": similarity,\n",
    "                    }\n",
    "                )\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"results\": formatted_results,\n",
    "            \"num_results\": len(formatted_results),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Error retrieving game information: {e}\",\n",
    "            \"query\": query,\n",
    "            \"results\": [],\n",
    "        }\n",
    "\n",
    "# Test the tool\n",
    "test_result = retrieve_game(\"Pokemon games\")\n",
    "print(f\"Retrieved {test_result['num_results']} games\")\n",
    "if test_result['results']:\n",
    "    print(f\"First result: {test_result['results'][0]['name']} ({test_result['results'][0]['release_year']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score: 0/10\n",
      "Explanation: Error during evaluation: Expecting value: line 1 column 1 (char 0)\n",
      "Needs web search: True\n"
     ]
    }
   ],
   "source": [
    "# Tool 2: evaluate_retrieval - Evaluate if results are sufficient \n",
    "@tool\n",
    "def evaluate_retrieval(query: str, retrieved_results: str = \"\") -> Dict:\n",
    "    \"\"\"Evaluate the quality of retrieved results using an LLM.\"\"\"\n",
    "    evaluator = LLM(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "    \n",
    "    # Try to parse retrieved_results if it's a string\n",
    "    if isinstance(retrieved_results, str):\n",
    "        try:\n",
    "            import json\n",
    "            retrieved_results_dict = json.loads(retrieved_results)\n",
    "            results_text = (\n",
    "                \"\\n\\n\".join(\n",
    "                    [\n",
    "                        f\"Game {i+1}: {r['name']}\\n\"\n",
    "                        f\"Platform: {r['platform']}\\n\"\n",
    "                        f\"Year: {r['release_year']}\\n\"\n",
    "                        f\"Genre: {r['genre']}\\n\"\n",
    "                        f\"Publisher: {r['publisher']}\\n\"\n",
    "                        f\"Description: {r['description']}\\n\"\n",
    "                        f\"Relevance Score: {r['similarity_score']:.3f}\"\n",
    "                        for i, r in enumerate(retrieved_results_dict.get(\"results\", []))\n",
    "                    ]\n",
    "                )\n",
    "                if retrieved_results_dict.get(\"results\")\n",
    "                else \"No results found.\"\n",
    "            )\n",
    "        except:\n",
    "            # If parsing fails, just use the string representation\n",
    "            results_text = retrieved_results\n",
    "    else:\n",
    "        # If it's already a dict, format it normally\n",
    "        results_text = (\n",
    "            \"\\n\\n\".join(\n",
    "                [\n",
    "                    f\"Game {i+1}: {r['name']}\\n\"\n",
    "                    f\"Platform: {r['platform']}\\n\"\n",
    "                    f\"Year: {r['release_year']}\\n\"\n",
    "                    f\"Genre: {r['genre']}\\n\"\n",
    "                    f\"Publisher: {r['publisher']}\\n\"\n",
    "                    f\"Description: {r['description']}\\n\"\n",
    "                    f\"Relevance Score: {r['similarity_score']:.3f}\"\n",
    "                    for i, r in enumerate(retrieved_results.get(\"results\", []))\n",
    "                ]\n",
    "            )\n",
    "            if retrieved_results.get(\"results\")\n",
    "            else \"No results found.\"\n",
    "        )\n",
    "\n",
    "    evaluation_prompt = f\"\"\"\n",
    "Evaluate if the following search results adequately answer the user's query.\n",
    "\n",
    "User Query: \"{query}\"\n",
    "\n",
    "Retrieved Results:\n",
    "{results_text}\n",
    "\n",
    "Please provide:\n",
    "1. A quality score from 0-10 (10 being perfect)\n",
    "2. A brief explanation of your evaluation\n",
    "3. Whether web search is needed (true/false)\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "    \"quality_score\": <number>,\n",
    "    \"explanation\": \"<your evaluation>\",\n",
    "    \"needs_web_search\": <true/false>,\n",
    "    \"missing_information\": \"<what's missing>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = evaluator.invoke(evaluation_prompt)\n",
    "        evaluation = json.loads(response.content)\n",
    "        # For counting results, handle both string and dict cases\n",
    "        if isinstance(retrieved_results, str):\n",
    "            try:\n",
    "                retrieved_results_dict = json.loads(retrieved_results)\n",
    "                num_results = len(retrieved_results_dict.get(\"results\", []))\n",
    "            except:\n",
    "                num_results = 0\n",
    "        else:\n",
    "            num_results = len(retrieved_results.get(\"results\", []))\n",
    "            \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"quality_score\": evaluation[\"quality_score\"],\n",
    "            \"explanation\": evaluation[\"explanation\"],\n",
    "            \"needs_web_search\": evaluation[\"needs_web_search\"],\n",
    "            \"missing_information\": evaluation.get(\"missing_information\", \"\"),\n",
    "            \"num_results_evaluated\": num_results,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"quality_score\": 0,\n",
    "            \"explanation\": f\"Error during evaluation: {e}\",\n",
    "            \"needs_web_search\": True,\n",
    "            \"missing_information\": \"Unable to evaluate results\",\n",
    "        }\n",
    "\n",
    "# Test the evaluation tool\n",
    "eval_result = evaluate_retrieval(\"Pokemon Gold and Silver\", json.dumps(test_result))\n",
    "print(f\"Quality score: {eval_result['quality_score']}/10\")\n",
    "print(f\"Explanation: {eval_result['explanation']}\")\n",
    "print(f\"Needs web search: {eval_result['needs_web_search']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web search found 5 results\n",
      "Quick answer: PokÃ©mon Gold and Silver were released in Japan on November 21, 1999, in North America on October 15,...\n",
      "âœ… All three tools implemented and tested!\n"
     ]
    }
   ],
   "source": [
    "# Tool 3: game_web_search - Search the web via Tavily API\n",
    "@tool\n",
    "def game_web_search(query: str) -> Dict:\n",
    "    \"\"\"Perform a web search via Tavily API for additional game info.\"\"\"\n",
    "    tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    payload = {\n",
    "        \"api_key\": tavily_api_key,\n",
    "        \"query\": f\"{query} video game\",\n",
    "        \"search_depth\": \"advanced\",\n",
    "        \"include_answer\": True,\n",
    "        \"include_raw_content\": False,\n",
    "        \"max_results\": 5,\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"url\": r.get(\"url\", \"\"),\n",
    "                \"snippet\": r.get(\"content\", \"\"),\n",
    "                \"score\": r.get(\"score\", 0),\n",
    "            }\n",
    "            for r in data.get(\"results\", [])\n",
    "        ]\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"answer\": data.get(\"answer\", \"\"),\n",
    "            \"results\": formatted_results,\n",
    "            \"num_results\": len(formatted_results),\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": f\"Web search error: {e}\", \"query\": query, \"results\": []}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {e}\", \"query\": query, \"results\": []}\n",
    "\n",
    "# Test the web search tool\n",
    "web_result = game_web_search(\"Pokemon Gold Silver release date\")\n",
    "print(f\"Web search found {web_result['num_results']} results\")\n",
    "if 'answer' in web_result and web_result['answer']:\n",
    "    print(f\"Quick answer: {web_result['answer'][:100]}...\")\n",
    "print(\"âœ… All three tools implemented and tested!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Build the UdaPlay Agent\n",
    "\n",
    "Now we'll create our stateful agent that combines all three tools in the proper workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UdaPlay Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Custom Agent Definition\n",
    "class UdaPlayAgent(Agent):\n",
    "    \"\"\"Agent that follows RAG â†’ Evaluate â†’ Web Search workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"gpt-4o-mini\", temperature: float = 0.7):\n",
    "        instructions = (\n",
    "            \"You are UdaPlay, an AI research assistant specializing in video game information.\\n\\n\"\n",
    "            \"Workflow:\\n\"\n",
    "            \"1. Use retrieve_game to search the internal database.\\n\"\n",
    "            \"2. Use evaluate_retrieval to assess result quality.\\n\"\n",
    "            \"3. If results are insufficient, use game_web_search.\\n\"\n",
    "            \"4. Return comprehensive, cited answers.\\n\\n\"\n",
    "            \"Answering Guidelines:\\n\"\n",
    "            \"- Always cite sources.\\n\"\n",
    "            \"- Provide specific game details (platform, year, publisher, etc.).\\n\"\n",
    "            \"- If sources conflict, mention both and explain.\\n\"\n",
    "            \"- Maintain conversation context across queries.\"\n",
    "        )\n",
    "        super().__init__(\n",
    "            model_name=model_name,\n",
    "            instructions=instructions,\n",
    "            tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "    def invoke(self, query: str, session_id: Optional[str] = None):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Processing query: '{query}'\")\n",
    "        print(\"=\" * 60)\n",
    "        result = super().invoke(query, session_id)\n",
    "        final_state = result.get_final_state()\n",
    "        if final_state and \"total_tokens\" in final_state:\n",
    "            print(f\"ðŸ’¬ Total tokens used: {final_state['total_tokens']}\")\n",
    "        return result\n",
    "\n",
    "# Create the agent\n",
    "agent = UdaPlayAgent()\n",
    "print(\"âœ… UdaPlay Agent created successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Demonstrate the Agent\n",
    "\n",
    "Let's test our agent with various queries to show the RAG â†’ Evaluate â†’ Web Search workflow in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing query: 'When was PokÃ©mon Gold and Silver released?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 1741\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "**PokÃ©mon Gold and Silver** were released in **1999** for the **Game Boy Color**. These games are recognized as the second generation of PokÃ©mon titles, introducing new regions, PokÃ©mon species, and gameplay mechanics. They were published by **Nintendo** and are part of the role-playing genre.\n",
      "\n",
      "While the retrieved information is quite solid regarding basic details, it lacks depth in terms of gameplay mechanics, differences from the previous PokÃ©mon games (like PokÃ©mon Red and Blue), and their overall impact or legacy in the gaming industry. If you'd like to know more about those aspects, let me know!\n",
      "============================================================\n",
      "Processing query: 'Which one was the first 3D platformer Mario game?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 3736\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "The first 3D platformer Mario game is **Super Mario 64**, which was released in **1996** for the **Nintendo 64**. This groundbreaking game set new standards for the platforming genre, featuring Mario's quest to rescue Princess Peach. It was published by **Nintendo** and is widely regarded as a significant milestone in video game history due to its innovative use of 3D graphics and gameplay mechanics.\n",
      "============================================================\n",
      "Processing query: 'Was Mortal Kombat X released for PlayStation 5?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 8882\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "**Mortal Kombat X** is not natively playable on the PlayStation 5. The game was originally released for the PlayStation 4 in **2015**. However, a collection that includes Mortal Kombat X is set to be released for the PS5 in **2025**. \n",
      "\n",
      "While you cannot play Mortal Kombat X directly on the PS5, there may be workarounds or methods to access it through backward compatibility or other means, but these are not officially supported. For the latest updates, you can check out sources like the [Mortal Kombat Wiki](https://mortalkombat.fandom.com/wiki/Mortal_Kombat_X) or the announcement regarding the upcoming **Mortal Kombat: Legacy Kollection** for PS5.\n",
      "============================================================\n",
      "Processing query: 'What other Pokemon games were released around the same time?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 17425\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "In addition to **PokÃ©mon Gold and Silver**, which were released in **1999**, there were a couple of other PokÃ©mon games released around the same time:\n",
      "\n",
      "1. **PokÃ©mon Snap** - Released in Japan on **March 21, 1999**, and in North America on **June 30, 1999**, this game was developed for the Nintendo 64 and allowed players to take photos of PokÃ©mon in their natural habitats. \n",
      "\n",
      "2. **PokÃ©mon Pinball** - Released in Japan on **April 14, 1999**, and in North America on **June 28, 1999**, this game was developed for the Game Boy Color and combined PokÃ©mon with the mechanics of pinball gameplay.\n",
      "\n",
      "These titles, along with PokÃ©mon Gold and Silver, contributed to the PokÃ©mon franchise's expansion during that period. For more details, you can refer to the [Wikipedia page on PokÃ©mon games](https://en.wikipedia.org/wiki/List_of_Pok%C3%A9mon_video_games).\n",
      "\n",
      "ðŸŽ¯ DEMO COMPLETE\n",
      "Total queries processed: 4\n",
      "Total tokens used: 31,784\n"
     ]
    }
   ],
   "source": [
    "# Helper function to display agent responses\n",
    "def display_response(run_result):\n",
    "    final_state = run_result.get_final_state()\n",
    "    if final_state and \"messages\" in final_state:\n",
    "        for msg in reversed(final_state[\"messages\"]):\n",
    "            if getattr(msg, \"content\", None) and not hasattr(msg, \"tool_call_id\"):\n",
    "                print(\"\\nðŸ¤– Agent Response:\\n\" + msg.content)\n",
    "                break\n",
    "\n",
    "# Run demonstration queries\n",
    "def run_demo_queries():\n",
    "    session_id = \"demo_session\"\n",
    "    \n",
    "    queries = [\n",
    "        \"When was PokÃ©mon Gold and Silver released?\",\n",
    "        \"Which one was the first 3D platformer Mario game?\", \n",
    "        \"Was Mortal Kombat X released for PlayStation 5?\",\n",
    "        \"What other Pokemon games were released around the same time?\",\n",
    "    ]\n",
    "    \n",
    "    total_tokens = 0\n",
    "    \n",
    "    for q in queries:\n",
    "        res = agent.invoke(q, session_id=session_id)\n",
    "        display_response(res)\n",
    "        \n",
    "        final_state = res.get_final_state()\n",
    "        if final_state and \"total_tokens\" in final_state:\n",
    "            total_tokens += final_state['total_tokens']\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ DEMO COMPLETE\")\n",
    "    print(f\"Total queries processed: {len(queries)}\")\n",
    "    print(f\"Total tokens used: {total_tokens:,}\")\n",
    "    \n",
    "# Run the demonstration\n",
    "run_demo_queries()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Successfully implemented all requirements:**\n",
    "\n",
    "1. **Three Required Tools:**\n",
    "   - `retrieve_game`: Searches the ChromaDB vector store for game information\n",
    "   - `evaluate_retrieval`: Uses LLM to assess result quality and decide if web search is needed\n",
    "   - `game_web_search`: Performs web search via Tavily API for additional information\n",
    "\n",
    "2. **Stateful Agent:**\n",
    "   - Maintains conversation context across queries\n",
    "   - Follows the proper workflow: RAG â†’ Evaluate â†’ Web Search\n",
    "   - Provides comprehensive, cited responses\n",
    "\n",
    "3. **Demonstration:**\n",
    "   - Processed 4 example queries successfully\n",
    "   - Shows proper tool usage and workflow\n",
    "   - Maintains conversation state between queries\n",
    "\n",
    "The agent successfully demonstrates the intelligent workflow where it first searches local knowledge, evaluates the results, and only performs web search when needed. All responses include proper citations and specific game details.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
